#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\begin_modules
theorems-ams
algolyx
theorems-ams-extended
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\M}{\mathcal{M}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\I}{\mathcal{I}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\X}{\mathcal{X}}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\O}{\mathcal{O}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\P}{\mathcal{P}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\E}{\mathcal{E}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\R}{\mathbb{R}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\L}{\mathcal{L}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\G}{\mathcal{G}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\Z}{\mathbb{Z}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\S}{\mathcal{S}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\p}{^{\prime}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\A}{\mathscr{A}}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\I}{\mathscr{I}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\T}{\mathcal{T}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\eps}{\varepsilon}
\end_inset


\begin_inset FormulaMacro
\newcommand{\e}{\varepsilon}
\end_inset


\begin_inset FormulaMacro
\newcommand{\d}{\delta}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ph}{\varphi}
\end_inset


\begin_inset FormulaMacro
\newcommand{\F}{\mathbb{F}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\N}{\mathbb{N}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\nequiv}{\not\equiv}
\end_inset


\begin_inset FormulaMacro
\newcommand{\perm}{\text{perm}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\pp}{^{\prime\prime}}
\end_inset


\end_layout

\begin_layout Title
The Constructive Lovasz Local Lemma
\end_layout

\begin_layout Section
Motivation
\end_layout

\begin_layout Standard
Assume there is a finite set 
\begin_inset Formula $\P=\{P_{i}\}$
\end_inset

 of 
\series bold
independent
\series default
 random variables (not necessarily binary), and for each 
\begin_inset Formula $i$
\end_inset

 there is an efficient procedure for sampling 
\begin_inset Formula $P_{i}$
\end_inset

.
 We are explicitly given a bipartite graph between events 
\begin_inset Formula $\E_{j}$
\end_inset

 and variables 
\begin_inset Formula $P_{i}$
\end_inset

 such that 
\begin_inset Formula $\E_{j}$
\end_inset

 is mutually independent of all variables it does not have an edge to.
 Write 
\begin_inset Formula $L(\E_{j})$
\end_inset

 for the 
\begin_inset Formula $P_{i}$
\end_inset

 that 
\begin_inset Formula $\E_{j}$
\end_inset

 has an edge to.
 For the dependency graph, 
\begin_inset Formula $(\E_{i},\E_{j})$
\end_inset

 exists only if 
\begin_inset Formula $L(\E_{i})\cap L(\E_{j})\neq\emptyset$
\end_inset

.
\end_layout

\begin_layout Standard
The Moser-Tardos Algorithm is quite simple: For each 
\begin_inset Formula $P\in\mathcal{P}$
\end_inset

, let 
\begin_inset Formula $y_{P}$
\end_inset

 be a random draw of 
\begin_inset Formula $P$
\end_inset

 (independent of all 
\begin_inset Formula $y_{P\p}$
\end_inset

).
 While there is some 
\begin_inset Formula $\E_{j}$
\end_inset

 that is true under 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, re-draw all 
\begin_inset Formula $P\in L(\E_{j})$
\end_inset

.
\end_layout

\begin_layout Theorem
(Moser-Tardos 2009).
 
\emph on
Assume that there exists 
\begin_inset Formula $x_{i}$
\end_inset

 with 
\begin_inset Formula 
\[
\Pr[\E_{i}]\leq x_{i}\prod_{(i,j)\in E}(1-x_{j})
\]

\end_inset

for all 
\begin_inset Formula $i$
\end_inset

.
 Then this algorithm finds an assignment 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 satisfying 
\begin_inset Formula $\bigcap\bar{\E_{j}}$
\end_inset

 and uses at most 
\begin_inset Formula 
\[
\sum_{j}\frac{x_{j}}{1-x_{j}}
\]

\end_inset

 iterations in expectation.
 More specifically, each 
\begin_inset Formula $\E_{j}$
\end_inset

 is resampled at most 
\begin_inset Formula $\frac{x_{j}}{1-x_{j}}$
\end_inset

 times in expectation.
\end_layout

\begin_layout Section
Execution Logs and Witness Trees
\end_layout

\begin_layout Subsection
Definitions
\end_layout

\begin_layout Standard
The 
\series bold
execution log
\series default
 
\begin_inset Formula $C$
\end_inset

 has 
\begin_inset Formula $C(t)$
\end_inset

 the event that 
\begin_inset Formula $\E_{j}$
\end_inset

 is resampled in step 
\begin_inset Formula $t$
\end_inset

.
 Resampling was necessary because 
\begin_inset Formula $\E_{j}$
\end_inset

 was true under 
\begin_inset Formula $\boldsymbol{y}_{t}$
\end_inset

.
 In the independent case, this was because the previous time we sampled
 
\begin_inset Formula $L(\E_{j})$
\end_inset

, we made 
\begin_inset Formula $\E_{j}$
\end_inset

 true).
 In the general case this is more subtle because resampling one or more
 
\begin_inset Formula $\E_{i}$
\end_inset

 with 
\begin_inset Formula $(j,i)\in E$
\end_inset

 may together have made 
\begin_inset Formula $\E_{j}$
\end_inset

 true.
\end_layout

\begin_layout Standard
We want a structure keeping track of the 
\begin_inset Quotes eld
\end_inset

blame
\begin_inset Quotes erd
\end_inset

 for resampling.
 We define a 
\series bold
witness tree
\series default
 
\begin_inset Formula $T_{t}$
\end_inset

 for time 
\begin_inset Formula $t$
\end_inset

 as follows: The root of 
\begin_inset Formula $T_{t}$
\end_inset

 is labeled 
\begin_inset Formula $\lambda(r)=\E_{j}$
\end_inset

.
 We iterate through 
\begin_inset Formula $t\p=t-1,t-2,\dots$
\end_inset

 and consider the event 
\begin_inset Formula $\E_{i}=C(t\p)$
\end_inset

 that happened at 
\begin_inset Formula $t\p$
\end_inset

 in 
\begin_inset Formula $C$
\end_inset

.
\end_layout

\begin_layout Standard
In the first case, there is no edge 
\begin_inset Formula $(i\p,i)\in E$
\end_inset

 for any 
\begin_inset Formula $\E_{i\p}$
\end_inset

 that is (so far) a label in 
\begin_inset Formula $T_{t}$
\end_inset

.
 Then, 
\begin_inset Formula $\E_{i}$
\end_inset

 cannot have caused any of the resampling in 
\begin_inset Formula $T_{t}$
\end_inset

, so we skip 
\begin_inset Formula $\E_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
In the second case, there is a node 
\begin_inset Formula $v\in T_{t}$
\end_inset

 with label 
\begin_inset Formula $\lambda(v)=\E_{i\p}$
\end_inset

 such that 
\begin_inset Formula $(i\p,i)\in E$
\end_inset

.
 Choose the deepest such 
\begin_inset Formula $v$
\end_inset

 (breaking ties arbitrarily), create a new node 
\begin_inset Formula $u$
\end_inset

 with 
\begin_inset Formula $\lambda(u)=\E_{i}$
\end_inset

, and make it a child of 
\begin_inset Formula $v$
\end_inset

.
\end_layout

\begin_layout Subsection
Properties
\end_layout

\begin_layout Fact

\emph on
If 
\begin_inset Formula $u,v$
\end_inset

 are at the same level of 
\begin_inset Formula $T$
\end_inset

, then 
\begin_inset Formula $L(\lambda(u))\cap L(\lambda(v))=\emptyset$
\end_inset

.
\end_layout

\begin_layout Proof
Consider the times 
\begin_inset Formula $t_{u}$
\end_inset

 and 
\begin_inset Formula $t_{v}$
\end_inset

; without loss of generality 
\begin_inset Formula $t_{u}<t_{v}$
\end_inset

 when 
\begin_inset Formula $\E_{i}$
\end_inset

 and 
\begin_inset Formula $\E_{i\p}$
\end_inset

 were resampled for the nodes 
\begin_inset Formula $u,v$
\end_inset

.
 Then in the construction of 
\begin_inset Formula $T$
\end_inset

, it was an option to attach 
\begin_inset Formula $u$
\end_inset

 to 
\begin_inset Formula $v$
\end_inset

.
 Because 
\begin_inset Formula $u$
\end_inset

 was attached as deep as possible, it cannot be at the same level as 
\begin_inset Formula $v$
\end_inset

.
\end_layout

\begin_layout Standard
We call a tree 
\begin_inset Formula $T$
\end_inset

 a 
\series bold
proper
\series default
 witness tree if it satisfies this condition.
 Sanity check: what does the witness tree look like for an empty independence
 graph? Well, since all variable sets are disjoint, each 
\begin_inset Formula $T_{t}$
\end_inset

 is a chain of nodes all labeled 
\begin_inset Formula $\E_{j}=\lambda(r)=C(t)$
\end_inset

.
 The chain has length equal to the number of times 
\begin_inset Formula $\E_{j}$
\end_inset

 was resampled in the first 
\begin_inset Formula $t$
\end_inset

 steps.
\end_layout

\begin_layout Standard
More generally, the tree for time 
\begin_inset Formula $t$
\end_inset

 has exactly as many nodes labeled 
\begin_inset Formula $C(t)$
\end_inset

 as the number of times 
\begin_inset Formula $C(t)$
\end_inset

 was resampled up to time 
\begin_inset Formula $t$
\end_inset

.
 This implies that each proper witness tree occurs at most once in the log.
 That is, the set of 
\begin_inset Formula $T_{t}$
\end_inset

 for 
\begin_inset Formula $t=0,1,\dots$
\end_inset

 has no two identical (including labels) trees.
\end_layout

\begin_layout Lemma

\emph on
Let 
\begin_inset Formula $T$
\end_inset

 be a proper witness tree.
 The probability that 
\begin_inset Formula $T$
\end_inset

 occurs in 
\begin_inset Formula $C$
\end_inset

 is at most 
\begin_inset Formula $\prod_{v\in T}\Pr[\lambda(v)]$
\end_inset

.
\end_layout

\begin_layout Proof
The idea is to couple the execution of the algorithm with a 
\begin_inset Quotes eld
\end_inset

tree check
\begin_inset Quotes erd
\end_inset

: making sure that all events 
\begin_inset Formula $\lambda(v)$
\end_inset

 happen.
 The tree check for each 
\begin_inset Formula $v\in T$
\end_inset

 samples all 
\begin_inset Formula $P\in L(\lambda(v))$
\end_inset

 independently and checks if 
\begin_inset Formula $\lambda(v)$
\end_inset

 is true.
 The check is passed iff all 
\begin_inset Formula $\lambda(v)$
\end_inset

 are true.
 Clearly, the probability of passing the tree check is 
\begin_inset Formula $\prod_{v\in T}\Pr[\lambda(v)]$
\end_inset

.
\end_layout

\begin_layout Proof
To do a coupling, consider the tree from lowest level to the root, sampling
 the variables in that order.
 (Note there are no ties because the tree is proper).
 To make the coupling precise, for each variable 
\begin_inset Formula $P\in\P$
\end_inset

 we have a sequence 
\begin_inset Formula $P^{(1)},P^{(2)},\dots$
\end_inset

 of values of 
\begin_inset Formula $P$
\end_inset

 drawn independently.
 When the tree check needs to sample 
\begin_inset Formula $P$
\end_inset

 for the 
\begin_inset Formula $i^{th}$
\end_inset

 time, it uses 
\begin_inset Formula $P^{(i)}$
\end_inset

.
 When Moser-Tardos needs to sample 
\begin_inset Formula $P$
\end_inset

 for the 
\begin_inset Formula $i^{th}$
\end_inset

 time, it also uses 
\begin_inset Formula $P^{(i)}$
\end_inset

.
\end_layout

\begin_layout Proof
Consider vertex 
\begin_inset Formula $v$
\end_inset

 with 
\begin_inset Formula $\lambda(v)=\E_{j}$
\end_inset

 occurring at time 
\begin_inset Formula $t$
\end_inset

.
 Then 
\begin_inset Formula $C(t)=\E_{j}$
\end_inset

.
 Let 
\begin_inset Formula $P\in L(\E_{j})$
\end_inset

 be a variable of 
\begin_inset Formula $\E_{j}$
\end_inset

 and 
\begin_inset Formula $m$
\end_inset

 be the number of timesteps 
\begin_inset Formula $t\p<t$
\end_inset

 such that 
\begin_inset Formula $P\in L(C(t\p))$
\end_inset

 – that is, the number of times 
\begin_inset Formula $P$
\end_inset

 was resampled up to time 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Proof
Then, Moser-Tardos at time 
\begin_inset Formula $t$
\end_inset

 has 
\begin_inset Formula $P=P^{(m+1)}$
\end_inset

 because the first sample is 
\begin_inset Quotes eld
\end_inset

free
\begin_inset Quotes erd
\end_inset

 and we resampled 
\begin_inset Formula $m$
\end_inset

 times.
 All of these resamplings must correspond to nodes 
\begin_inset Formula $u$
\end_inset

 strictly below 
\begin_inset Formula $v$
\end_inset

 in the witness tree because they occurred earlier – the witness tree had
 the option to attach them to 
\begin_inset Formula $v$
\end_inset

.
\end_layout

\begin_layout Proof
So, the tree check algorithm also sampled 
\begin_inset Formula $P$
\end_inset

 earlier 
\begin_inset Formula $m$
\end_inset

 times, and is using 
\begin_inset Formula $P^{(m+1)}$
\end_inset

 to evaluate 
\begin_inset Formula $v$
\end_inset

.
 This applies to all 
\begin_inset Formula $P\in L(\E_{j})$
\end_inset

 and all vertices 
\begin_inset Formula $v\in T$
\end_inset

.
 Because all 
\begin_inset Formula $\E_{j}$
\end_inset

 are true in Moser-Tardos (otherwise the resampling would not have happened),
 the probability that 
\begin_inset Formula $T$
\end_inset

 occurs in 
\begin_inset Formula $C$
\end_inset

 is at most the probability that 
\begin_inset Formula $T$
\end_inset

 passes the tree check.
\end_layout

\begin_layout Subsection
here
\end_layout

\begin_layout Standard
Write 
\begin_inset Formula $x_{j}\p\coloneqq x_{j}\prod_{(i,j)\in E}(1-x_{i})$
\end_inset

.
 Let 
\begin_inset Formula $\T_{j}$
\end_inset

 be the set of all proper witness trees whose root is labeled 
\begin_inset Formula $\lambda(r)=\E_{j}$
\end_inset

.
 Also, let 
\begin_inset Formula $N_{j}$
\end_inset

 be the random variable for the number of times 
\begin_inset Formula $L(\E_{j})$
\end_inset

 is resampled in Moser-Tardos.
\end_layout

\begin_layout Standard
Because each resampling corresponds to a tree with root label 
\begin_inset Formula $\E_{j}$
\end_inset

 and the same tree cannot appear multiple times,
\begin_inset Formula 
\begin{align*}
\mathbb{E}[N_{j}] & =\sum_{T\in\T_{j}}\Pr[T\text{ appears in log}]\\
 & \leq\sum_{T\in\T_{j}}\prod_{v\in T}\Pr[\lambda(v)] & \text{Lemma 3}\\
 & \leq\sum_{T\in\T_{j}}\prod_{v\in T}x_{\lambda(v)}^{\prime}. & \text{MT Assumption}
\end{align*}

\end_inset

Our goal now is to bound 
\begin_inset Formula $\prod_{v\in T}x_{\lambda(v)}^{\prime}$
\end_inset

 for a given tree 
\begin_inset Formula $T$
\end_inset

.
 We will define a probability distribution 
\begin_inset Formula $p_{T}$
\end_inset

 over labeled trees 
\begin_inset Formula $T$
\end_inset

 (finite and infinite, including some not in 
\begin_inset Formula $\T_{j}$
\end_inset

) such that
\begin_inset Formula 
\[
\prod_{v\in T}x_{\lambda(v)}^{\prime}=\frac{x_{j}}{1-x_{j}}p_{T}.
\]

\end_inset

Then we obtain
\begin_inset Formula 
\begin{align*}
\sum_{T\in\T_{j}}\prod_{v\in T}x_{\lambda(v)}^{\prime} & =\sum_{T\in\T_{j}}\frac{x_{j}}{1-x_{j}}p_{T}\\
 & =\frac{x_{j}}{1-x_{j}}\sum_{T\in\T_{j}}p_{T}\\
 & \leq\frac{x_{j}}{1-x_{j}}
\end{align*}

\end_inset

because the distribution generates some trees not in 
\begin_inset Formula $\T_{j}$
\end_inset

.
 Thus
\begin_inset Formula 
\[
\mathbb{E}[N_{j}]\leq\frac{x_{j}}{1-x_{j}},
\]

\end_inset

proving the theorem.
\end_layout

\begin_layout Standard
We define a generative process for trees as follows:
\end_layout

\begin_layout Enumerate
Start with a root labeled 
\begin_inset Formula $\E_{j}$
\end_inset


\end_layout

\begin_layout Enumerate
For all levels 
\begin_inset Formula $\ell=0,1,2,\dots$
\end_inset

 and for all nodes 
\begin_inset Formula $v$
\end_inset

 at level 
\begin_inset Formula $\ell$
\end_inset

 and for all events 
\begin_inset Formula $\E_{i}$
\end_inset

 with 
\begin_inset Formula $\E_{i}=\lambda(v)$
\end_inset

 or 
\begin_inset Formula $(\E_{i},\lambda(v))\in E$
\end_inset

: independently with probability 
\begin_inset Formula $x_{i}$
\end_inset

 give 
\begin_inset Formula $v$
\end_inset

 a child 
\begin_inset Formula $u$
\end_inset

 with 
\begin_inset Formula $\lambda(u)=\E_{i}$
\end_inset

; otherwise give 
\begin_inset Formula $v$
\end_inset

 no child with label 
\begin_inset Formula $\E_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
This is called a Galton-Watson branching process.
 It may die out after a finite number of levels, or build infinite trees.
 It induces a distribution 
\begin_inset Formula $p_{T}$
\end_inset

 over (finite and infinite) labeled trees.
\end_layout

\begin_layout Lemma

\emph on
For every finite labeled tree, 
\begin_inset Formula 
\[
p_{T}=\frac{1-x_{j}}{x_{j}}\prod_{v\in T}x_{\lambda(v)}^{\prime}.
\]

\end_inset


\end_layout

\begin_layout Proof
Fix a finite labeled tree 
\begin_inset Formula $T$
\end_inset

 in which no node has two children of the same label.
 For any vertex 
\begin_inset Formula $v\in T$
\end_inset

, let 
\begin_inset Formula 
\[
W_{v}\coloneqq\{i:\lambda(v)=\E_{i}\text{ or }(\lambda(v),\E_{i})\in E\text{ but \ensuremath{v} has no child labeled \ensuremath{i}}\}.
\]

\end_inset

This is the set of events that 
\begin_inset Formula $v$
\end_inset

 could have had as child labels, but didn't.
 Then,
\begin_inset Formula 
\begin{align*}
p_{T} & =\prod_{v\neq r}x_{\lambda(v)}\prod_{v}\prod_{i\in W_{v}}(1-x_{i})\\
 & =\frac{1}{x_{j}}\prod_{v}\big(x_{\lambda(v)}\prod_{i\in W_{v}}(1-x_{i})\big).
\end{align*}

\end_inset

We multiply/divide the missing 
\begin_inset Formula $(1-x_{i})$
\end_inset

 terms, so
\begin_inset Formula 
\[
p_{T}=\frac{1}{x_{j}}\cdot\prod_{v}\big(x_{\lambda(v)}\cdot\prod_{\E_{i}:\E_{i}=\lambda(v)\text{ or }(\E_{i},\lambda(v))\in E}(1-x_{i})\cdot\frac{1}{1-x_{\lambda(v)}}\big)\cdot(1-x_{j})
\]

\end_inset

Essentially we added a 
\begin_inset Formula $(1-x_{i})$
\end_inset

 for each of the children, so the final term in the inner product cancels
 exactly one added term.
 The root is not a child of anything, so the final term overall accounts
 for it.
 Thus,
\begin_inset Formula 
\begin{align*}
p_{T} & =\frac{1-x_{j}}{x_{j}}\prod_{v}\big(\frac{x_{\lambda(v)}}{1-x_{\lambda(v)}}\cdot(1-x_{\lambda(v)})\cdot\prod_{i:(\E_{i},\lambda(v))\in E}(1-x_{i})\big)\\
 & =\frac{1-x_{j}}{x_{j}}\prod_{v}\big(x_{\lambda(v)}\prod_{i:(\E_{i},\lambda(v))\in E}(1-x_{i})\big)\\
 & =\frac{1-x_{j}}{x_{j}}\prod_{v}x_{\lambda(v)}^{\prime}.
\end{align*}

\end_inset


\end_layout

\end_body
\end_document
